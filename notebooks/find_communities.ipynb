{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b3071fbd57d3f1f",
   "metadata": {},
   "source": [
    "## Finding and Evaluating Communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88bbe7ca3ab46aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms import community\n",
    "from neo4j import GraphDatabase\n",
    "import concurrent.futures\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "URI = \"bolt://localhost:7687\"\n",
    "\n",
    "password = \"12345678\" # CHANGE\n",
    "AUTH = (\"neo4j\", password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74d78bc3accae52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_from_neo4j(driver):\n",
    "    G = nx.DiGraph()\n",
    "    with driver.session() as session:\n",
    "        nodes_result = session.run(\"\"\"\n",
    "            MATCH (n)\n",
    "            RETURN id(n) AS id, labels(n) AS labels, properties(n) AS properties\n",
    "        \"\"\")\n",
    "        for record in nodes_result:    \n",
    "            G.add_node(record[\"id\"], labels=record[\"labels\"], **record[\"properties\"])\n",
    "\n",
    "        rels_result = session.run(\"\"\"\n",
    "            MATCH (n)-[r]->(m)\n",
    "            RETURN id(n) AS source, id(m) AS target, type(r) AS type\n",
    "        \"\"\")\n",
    "        for record in rels_result:\n",
    "            G.add_edge(record[\"source\"], record[\"target\"], type=record[\"type\"])\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f23bca9-7a22-49b2-b263-62dbef9b8118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_graph_for_gexf(graph):\n",
    "    for node, data in graph.nodes(data=True):\n",
    "        labels = data.get('labels', [])\n",
    "        if isinstance(labels, list):\n",
    "            labels_str = ','.join(labels)\n",
    "        else:\n",
    "            labels_str = str(labels)\n",
    "\n",
    "        data['labels'] = labels_str\n",
    "\n",
    "    for u, v, data in graph.edges(data=True):\n",
    "        if 'type' in data:\n",
    "            data['label'] = data.pop('type')\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14d63333dd90a2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_partition(G, communities, method_name):\n",
    "    if not communities or len(communities) == 0:\n",
    "        print(f\"No communities found by {method_name}.\")\n",
    "        return\n",
    "\n",
    "    partition = [set(c) for c in communities]\n",
    "\n",
    "    print(f\"Evaluating {method_name} ---\")\n",
    "    try:\n",
    "        mod = community.modularity(G, partition)\n",
    "        print(f\"Modularity: {mod:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not calculate Modularity: {e}\")\n",
    "\n",
    "    try:\n",
    "        qual = community.partition_quality(G, partition)\n",
    "        print(f\"Partition Quality (Coverage, Performance): ({qual[0]:.4f}, {qual[1]:.4f})\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not calculate Partition Quality: {e}\")\n",
    "    print(f\"Found {len(partition)} communities.\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe819fd91ea07627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stamp_partition_to_graph(G, partition, attribute_name):\n",
    "    nx.set_node_attributes(G, None, attribute_name)\n",
    "\n",
    "    for i, community_set in enumerate(partition):\n",
    "        for node in community_set:\n",
    "            if node in G.nodes:\n",
    "                G.nodes[node][attribute_name] = i\n",
    "            else:\n",
    "                print(f\"Node {node} from partition not in graph.\")\n",
    "\n",
    "def stamp_overlapping_partition_to_graph(G, partition, attribute_name):\n",
    "    nx.set_node_attributes(G, \"[]\", attribute_name)\n",
    "\n",
    "    node_to_communities = {}\n",
    "    for i, community_set in enumerate(partition):\n",
    "        for node in community_set:\n",
    "            if node not in node_to_communities:\n",
    "                node_to_communities[node] = []\n",
    "            node_to_communities[node].append(i)\n",
    "\n",
    "    final_attributes = {}\n",
    "    for node, communities in node_to_communities.items():\n",
    "        if node in G.nodes:\n",
    "            final_attributes[node] = str(communities)\n",
    "        else:\n",
    "            print(f\"Node {node} from partition not in graph.\")\n",
    "\n",
    "    nx.set_node_attributes(G, final_attributes, attribute_name)\n",
    "\n",
    "def stamp_id_group_to_graph(G):\n",
    "    nx.set_node_attributes(G, \"None\", \"id_group_anonymous\")\n",
    "\n",
    "    for node, data in G.nodes(data=True):\n",
    "        if \"id_group_anonymous\" in data:\n",
    "            G.nodes[node][\"id_group_anonymous\"] = str(data[\"id_group_anonymous\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc011199-343f-43be-8260-16efc74ccf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_girvan_newman(G):\n",
    "    try:\n",
    "        print(\"  [Thread] Starting Girvan-Newman...\")\n",
    "        comp_generator = community.girvan_newman(G)\n",
    "        partition = next(comp_generator) # Get first level of partition\n",
    "        print(\"  [Thread] Finished Girvan-Newman.\")\n",
    "        return (\"girvan_newman\", partition, \"partition\", None)\n",
    "    except Exception as e:\n",
    "        return (\"girvan_newman\", None, None, e)\n",
    "\n",
    "def worker_edge_betweenness(G, k):\n",
    "    try:\n",
    "        print(f\"  [Thread] Starting Edge Betweenness (for k={k})...\")\n",
    "        comp_generator = community.girvan_newman(G)\n",
    "        # Iterate until we get k communities\n",
    "        for _ in range(k - 1):\n",
    "             partition = next(comp_generator)\n",
    "        print(f\"  [Thread] Finished Edge Betweenness (for k={k}).\")\n",
    "        return (\"edge_betweenness\", partition, \"partition\", None)\n",
    "    except Exception as e:\n",
    "        return (\"edge_betweenness\", None, None, e)\n",
    "\n",
    "\"\"\"def worker_edge_current_flow(G, k):\n",
    "    try:\n",
    "        print(f\"  [Thread] Starting Edge Current Flow (for k={k})...\")\n",
    "        partition = edge_current_flow_betweenness_partition(G, k)\n",
    "        print(f\"  [Thread] Finished Edge Current Flow (for k={k}).\")\n",
    "        return (\"edge_current_flow\", partition, \"partition\", None)\n",
    "    except Exception as e:\n",
    "        return (\"edge_current_flow\", None, None, e)\"\"\"\n",
    "\n",
    "def worker_greedy_modularity(G):\n",
    "    try:\n",
    "        print(\"  [Thread] Starting Greedy Modularity...\")\n",
    "        partition = community.greedy_modularity_communities(G)\n",
    "        print(\"  [Thread] Finished Greedy Modularity.\")\n",
    "        return (\"greedy_modularity\", partition, \"partition\", None)\n",
    "    except Exception as e:\n",
    "        return (\"greedy_modularity\", None, None, e)\n",
    "\n",
    "def worker_naive_greedy_modularity(G):\n",
    "    try:\n",
    "        print(\"  [Thread] Starting Naive Greedy Modularity...\")\n",
    "        partition = community.naive_greedy_modularity_communities(G)\n",
    "        print(\"  [Thread] Finished Naive Greedy Modularity.\")\n",
    "        return (\"naive_greedy_modularity\", partition, \"partition\", None)\n",
    "    except Exception as e:\n",
    "        return (\"naive_greedy_modularity\", None, None, e)\n",
    "\n",
    "def worker_lukes(G):\n",
    "    try:\n",
    "        print(\"  [Thread] Starting Lukes Partitioning...\")\n",
    "        partition = community.lukes_partitioning(G, max_size=2000)\n",
    "        print(\"  [Thread] Finished Lukes Partitioning.\")\n",
    "        return (\"lukes\", partition, \"partition\", None)\n",
    "    except Exception as e:\n",
    "        return (\"lukes\", None, None, e)\n",
    "\n",
    "def worker_label_propagation(G):\n",
    "    try:\n",
    "        print(\"  [Thread] Starting Label Propagation...\")\n",
    "        comp_generator = community.label_propagation_communities(G)\n",
    "        partition = [set(c) for c in comp_generator]\n",
    "        print(\"  [Thread] Finished Label Propagation.\")\n",
    "        return (\"label_propagation\", partition, \"partition\", None)\n",
    "    except Exception as e:\n",
    "        return (\"label_propagation\", None, None, e)\n",
    "\n",
    "def worker_fast_label_propagation(G):\n",
    "    try:\n",
    "        print(\"  [Thread] Starting Fast Label (asyn_lpa)...\")\n",
    "        comp_generator = community.asyn_lpa_communities(G)\n",
    "        partition = [set(c) for c in comp_generator]\n",
    "        print(\"  [Thread] Finished Fast Label (asyn_lpa).\")\n",
    "        return (\"fast_label_propagation\", partition, \"partition\", None)\n",
    "    except Exception as e:\n",
    "        return (\"fast_label_propagation\", None, None, e)\n",
    "\n",
    "def worker_louvain(G):\n",
    "    try:\n",
    "        print(\"  [Thread] Starting Louvain...\")\n",
    "        partition = community.louvain_communities(G)\n",
    "        print(\"  [Thread] Finished Louvain.\")\n",
    "        return (\"louvain\", partition, \"partition\", None)\n",
    "    except Exception as e:\n",
    "        return (\"louvain\", None, None, e)\n",
    "\n",
    "def worker_fluidc(G, k):\n",
    "    try:\n",
    "        print(f\"  [Thread] Starting Fluidc (k={k})...\")\n",
    "        if k > G.number_of_nodes():\n",
    "            return (\"fluidc\", None, None, Exception(f\"k ({k}) > node count\"))\n",
    "        comp_generator = community.asyn_fluidc(G, k)\n",
    "        partition = [set(c) for c in comp_generator]\n",
    "        print(f\"  [Thread] Finished Fluidc (k={k}).\")\n",
    "        return (\"fluidc\", partition, \"partition\", None)\n",
    "    except Exception as e:\n",
    "        return (\"fluidc\", None, None, e)\n",
    "\n",
    "def worker_k_clique(G, k):\n",
    "    try:\n",
    "        print(f\"  [Thread] Starting K-Clique (k={k})...\")\n",
    "        comp_generator = community.k_clique_communities(G, k)\n",
    "        communities = [set(c) for c in comp_generator]\n",
    "        print(f\"  [Thread] Finished K-Clique (k={k}).\")\n",
    "        return (\"k_clique\", communities, \"overlapping\", None)\n",
    "    except Exception as e:\n",
    "        return (\"k_clique\", None, None, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "981a28d8-964f-44af-8452-4190f1541021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noinspection PyUnresolvedReferences\n",
    "def analyze_graph_communities_parallel(G, graph_name, k_target):\n",
    "    \n",
    "    print(f\"\\n{'='*25} PROCESSING GRAPH: {graph_name} {'='*25}\")\n",
    "    print(f\"Graph has {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n",
    "    \n",
    "    if G.number_of_edges() == 0:\n",
    "        print(\"Skipping graph, no edges.\")\n",
    "        return\n",
    "\n",
    "    futures = {}\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
    "        print(f\"Submitting all community tasks for {graph_name} to ThreadPool...\")\n",
    "        \n",
    "        futures[executor.submit(worker_girvan_newman, G)] = \"Girvan-Newman\"\n",
    "        #futures[executor.submit(worker_edge_betweenness, G, k_target)] = \"Edge Betweenness\"\n",
    "        #futures[executor.submit(worker_edge_current_flow, G, k_target)] = \"Edge Current Flow\"\n",
    "        futures[executor.submit(worker_greedy_modularity, G)] = \"Greedy Modularity\"\n",
    "        #futures[executor.submit(worker_naive_greedy_modularity, G)] = \"Naive Greedy Modularity\"\n",
    "        futures[executor.submit(worker_lukes, G)] = \"Lukes Partitioning\"\n",
    "        futures[executor.submit(worker_label_propagation, G)] = \"Label Propagation\"\n",
    "        futures[executor.submit(worker_fast_label_propagation, G)] = \"Fast Label Propagation\"\n",
    "        futures[executor.submit(worker_louvain, G)] = \"Louvain\"\n",
    "        futures[executor.submit(worker_fluidc, G, k_target)] = \"Asynchronous Fluidc\"\n",
    "        #futures[executor.submit(worker_k_clique, G, k_target)] = \"K-Clique\"\n",
    "\n",
    "        print(\"All tasks submitted. Waiting for results...\")\n",
    "        \n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            task_name = futures[future]\n",
    "            try:\n",
    "                name, data, partition_type, error = future.result()\n",
    "                \n",
    "                if error:\n",
    "                    print(f\"\\n--- ERROR running {task_name} ---\")\n",
    "                    print(f\"  > {error}\")\n",
    "                    print(\"-\" * 30)\n",
    "                    continue\n",
    "                \n",
    "                print(f\"\\nProcessing result for {task_name}...\")\n",
    "                \n",
    "                if partition_type == \"partition\":\n",
    "                    evaluate_partition(G, data, name)\n",
    "                    stamp_partition_to_graph(G, data, f\"{name}_community\")\n",
    "                \n",
    "                elif partition_type == \"overlapping\":\n",
    "                    print(f\"--- Evaluating {name} (Overlapping) ---\")\n",
    "                    print(f\"  > Found {len(data)} overlapping {k_target}-clique communities.\")\n",
    "                    print(\"  > Modularity/Quality metrics not applicable.\")\n",
    "                    print(\"-\" * 30)\n",
    "                    stamp_overlapping_partition_to_graph(G, data, f\"{name}_community\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"\\n--- CRITICAL ERROR processing result for {task_name} ---\")\n",
    "                print(f\"  > {e}\")\n",
    "                print(\"-\" * 30)\n",
    "\n",
    "    output_dir = \"../visualization\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    export_filename = os.path.join(output_dir, f\"{graph_name}_with_communities.gexf\")\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\nExporting {graph_name} to GEXF...\")\n",
    "        stamp_id_group_to_graph(G)\n",
    "        G_exportable = prepare_graph_for_gexf(G.copy())\n",
    "        \n",
    "        nx.write_gexf(G_exportable, export_filename)\n",
    "        print(f\"\\n>>> Successfully exported graph to {export_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n>>> FAILED to export GEXF file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9968dbae3fa771a9",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Neo4j and building NetworkX graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: <GqlStatusObject gql_status='01N01', status_description='warn: feature deprecated with replacement. id is deprecated. It is replaced by elementId or consider using an application-generated id.', position=<SummaryInputPosition line=3, column=20, offset=42>, raw_classification='DEPRECATION', classification=<NotificationClassification.DEPRECATION: 'DEPRECATION'>, raw_severity='WARNING', severity=<NotificationSeverity.WARNING: 'WARNING'>, diagnostic_record={'_classification': 'DEPRECATION', '_severity': 'WARNING', '_position': {'offset': 42, 'line': 3, 'column': 20}, 'OPERATION': '', 'OPERATION_CODE': '0', 'CURRENT_SCHEMA': '/'}> for query: '\\n            MATCH (n)\\n            RETURN id(n) AS id, labels(n) AS labels, properties(n) AS properties\\n        '\n",
      "Received notification from DBMS server: <GqlStatusObject gql_status='01N01', status_description='warn: feature deprecated with replacement. id is deprecated. It is replaced by elementId or consider using an application-generated id.', position=<SummaryInputPosition line=3, column=20, offset=51>, raw_classification='DEPRECATION', classification=<NotificationClassification.DEPRECATION: 'DEPRECATION'>, raw_severity='WARNING', severity=<NotificationSeverity.WARNING: 'WARNING'>, diagnostic_record={'_classification': 'DEPRECATION', '_severity': 'WARNING', '_position': {'offset': 51, 'line': 3, 'column': 20}, 'OPERATION': '', 'OPERATION_CODE': '0', 'CURRENT_SCHEMA': '/'}> for query: '\\n            MATCH (n)-[r]->(m)\\n            RETURN id(n) AS source, id(m) AS target, type(r) AS type\\n        '\n",
      "Received notification from DBMS server: <GqlStatusObject gql_status='01N01', status_description='warn: feature deprecated with replacement. id is deprecated. It is replaced by elementId or consider using an application-generated id.', position=<SummaryInputPosition line=3, column=37, offset=68>, raw_classification='DEPRECATION', classification=<NotificationClassification.DEPRECATION: 'DEPRECATION'>, raw_severity='WARNING', severity=<NotificationSeverity.WARNING: 'WARNING'>, diagnostic_record={'_classification': 'DEPRECATION', '_severity': 'WARNING', '_position': {'offset': 68, 'line': 3, 'column': 37}, 'OPERATION': '', 'OPERATION_CODE': '0', 'CURRENT_SCHEMA': '/'}> for query: '\\n            MATCH (n)-[r]->(m)\\n            RETURN id(n) AS source, id(m) AS target, type(r) AS type\\n        '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph imported into NetworkX\n",
      "\n",
      "========================= PROCESSING GRAPH: Shares =========================\n",
      "Graph has 3506 nodes and 72911 edges.\n",
      "Submitting all community tasks for Shares to ThreadPool...\n",
      "  [Thread] Starting Girvan-Newman...\n",
      "  [Thread] Starting Greedy Modularity...\n",
      "  [Thread] Starting Lukes Partitioning...\n",
      "  [Thread] Starting Fast Label (asyn_lpa)...\n",
      "  [Thread] Starting Louvain...\n",
      "  [Thread] Starting Label Propagation...\n",
      "  [Thread] Starting Fluidc (k=4)...\n",
      "All tasks submitted. Waiting for results...\n",
      "\n",
      "--- ERROR running Lukes Partitioning ---\n",
      "  > lukes_partitioning works only on trees\n",
      "------------------------------\n",
      "\n",
      "--- ERROR running Asynchronous Fluidc ---\n",
      "  > Fluid Communities require connected Graphs.\n",
      "------------------------------\n",
      "  [Thread] Finished Label Propagation.\n",
      "\n",
      "Processing result for Label Propagation...\n",
      "Evaluating label_propagation ---\n",
      "Modularity: 0.0428\n",
      "Partition Quality (Coverage, Performance): (0.9920, 0.3701)\n",
      "Found 195 communities.\n",
      "------------------------------\n",
      "  [Thread] Finished Fast Label (asyn_lpa).\n",
      "\n",
      "Processing result for Fast Label Propagation...\n",
      "Evaluating fast_label_propagation ---\n",
      "Modularity: 0.1924\n",
      "Partition Quality (Coverage, Performance): (0.9446, 0.4529)\n",
      "Found 208 communities.\n",
      "------------------------------\n",
      "  [Thread] Finished Louvain.\n",
      "\n",
      "Processing result for Louvain...\n",
      "Evaluating louvain ---\n",
      "Modularity: 0.4613\n",
      "Partition Quality (Coverage, Performance): (0.5682, 0.9295)\n",
      "Found 142 communities.\n",
      "------------------------------\n",
      "  [Thread] Finished Greedy Modularity.\n",
      "\n",
      "Processing result for Greedy Modularity...\n",
      "Evaluating greedy_modularity ---\n",
      "Modularity: 0.3879\n",
      "Partition Quality (Coverage, Performance): (0.6737, 0.8151)\n",
      "Found 158 communities.\n",
      "------------------------------\n",
      "  [Thread] Finished Girvan-Newman.\n",
      "\n",
      "Processing result for Girvan-Newman...\n",
      "Evaluating girvan_newman ---\n",
      "Modularity: 0.0148\n",
      "Partition Quality (Coverage, Performance): (1.0000, 0.2066)\n",
      "Found 128 communities.\n",
      "------------------------------\n",
      "\n",
      "Exporting Shares to GEXF...\n",
      "\n",
      ">>> Successfully exported graph to ../visualization/Shares_with_communities.gexf\n",
      "\n",
      "========================= PROCESSING GRAPH: Viral =========================\n",
      "Graph has 14 nodes and 78 edges.\n",
      "Submitting all community tasks for Viral to ThreadPool...\n",
      "  [Thread] Starting Girvan-Newman...\n",
      "  [Thread] Finished Girvan-Newman.\n",
      "  [Thread] Starting Greedy Modularity...\n",
      "  [Thread] Finished Greedy Modularity.\n",
      "  [Thread] Starting Lukes Partitioning...\n",
      "  [Thread] Starting Louvain...\n",
      "  [Thread] Finished Louvain.\n",
      "  [Thread] Starting Fast Label (asyn_lpa)...\n",
      "  [Thread] Finished Fast Label (asyn_lpa).\n",
      "  [Thread] Starting Label Propagation...\n",
      "  [Thread] Finished Label Propagation.\n",
      "All tasks submitted. Waiting for results...\n",
      "\n",
      "Processing result for Label Propagation...\n",
      "Evaluating label_propagation ---\n",
      "Modularity: 0.0000\n",
      "Partition Quality (Coverage, Performance): (1.0000, 0.8571)\n",
      "Found 1 communities.\n",
      "------------------------------\n",
      "\n",
      "Processing result for Fast Label Propagation...\n",
      "Evaluating fast_label_propagation ---\n",
      "Modularity: 0.0000\n",
      "Partition Quality (Coverage, Performance): (1.0000, 0.8571)\n",
      "Found 1 communities.\n",
      "------------------------------\n",
      "\n",
      "Processing result for Louvain...\n",
      "Evaluating louvain ---\n",
      "Modularity: 0.0125\n",
      "Partition Quality (Coverage, Performance): (0.7179, 0.7363)\n",
      "Found 2 communities.\n",
      "------------------------------\n",
      "\n",
      "Processing result for Girvan-Newman...\n",
      "Evaluating girvan_newman ---\n",
      "Modularity: -0.0003\n",
      "Partition Quality (Coverage, Performance): (0.9744, 0.9560)\n",
      "Found 2 communities.\n",
      "------------------------------\n",
      "\n",
      "Processing result for Greedy Modularity...\n",
      "Evaluating greedy_modularity ---\n",
      "Modularity: 0.0125\n",
      "Partition Quality (Coverage, Performance): (0.7179, 0.7363)\n",
      "Found 2 communities.\n",
      "------------------------------\n",
      "\n",
      "--- ERROR running Lukes Partitioning ---\n",
      "  > lukes_partitioning works only on trees\n",
      "------------------------------\n",
      "  [Thread] Starting Fluidc (k=4)...\n",
      "  [Thread] Finished Fluidc (k=4).\n",
      "\n",
      "Processing result for Asynchronous Fluidc...\n",
      "Evaluating fluidc ---\n",
      "Modularity: -0.0390\n",
      "Partition Quality (Coverage, Performance): (0.2564, 0.3626)\n",
      "Found 4 communities.\n",
      "------------------------------\n",
      "\n",
      "Exporting Viral to GEXF...\n",
      "\n",
      ">>> Successfully exported graph to ../visualization/Viral_with_communities.gexf\n",
      "\n",
      "========================= PROCESSING GRAPH: Misinfo =========================\n",
      "Graph has 937 nodes and 7802 edges.\n",
      "Submitting all community tasks for Misinfo to ThreadPool...\n",
      "  [Thread] Starting Girvan-Newman...\n",
      "  [Thread] Starting Greedy Modularity...\n",
      "  [Thread] Starting Lukes Partitioning...\n",
      "  [Thread] Starting Fast Label (asyn_lpa)...\n",
      "  [Thread] Finished Fast Label (asyn_lpa).\n",
      "  [Thread] Starting Label Propagation...\n",
      "  [Thread] Starting Louvain...\n",
      "  [Thread] Finished Label Propagation.\n",
      "  [Thread] Starting Fluidc (k=4)...\n",
      "All tasks submitted. Waiting for results...\n",
      "\n",
      "Processing result for Fast Label Propagation...\n",
      "Evaluating fast_label_propagation ---\n",
      "Modularity: 0.6177\n",
      "Partition Quality (Coverage, Performance): (0.7153, 0.9725)\n",
      "Found 110 communities.\n",
      "------------------------------\n",
      "\n",
      "--- ERROR running Lukes Partitioning ---\n",
      "  > lukes_partitioning works only on trees\n",
      "------------------------------\n",
      "\n",
      "--- ERROR running Asynchronous Fluidc ---\n",
      "  > Fluid Communities require connected Graphs.\n",
      "------------------------------\n",
      "\n",
      "Processing result for Label Propagation...\n",
      "Evaluating label_propagation ---\n",
      "Modularity: 0.5546\n",
      "Partition Quality (Coverage, Performance): (0.7789, 0.9112)\n",
      "Found 93 communities.\n",
      "------------------------------\n",
      "  [Thread] Finished Louvain.\n",
      "\n",
      "Processing result for Louvain...\n",
      "Evaluating louvain ---\n",
      "Modularity: 0.6576\n",
      "Partition Quality (Coverage, Performance): (0.7649, 0.9341)\n",
      "Found 45 communities.\n",
      "------------------------------\n",
      "  [Thread] Finished Greedy Modularity.\n",
      "\n",
      "Processing result for Greedy Modularity...\n",
      "Evaluating greedy_modularity ---\n",
      "Modularity: 0.5612\n",
      "Partition Quality (Coverage, Performance): (0.7143, 0.8755)\n",
      "Found 46 communities.\n",
      "------------------------------\n",
      "  [Thread] Finished Girvan-Newman.\n",
      "\n",
      "Processing result for Girvan-Newman...\n",
      "Evaluating girvan_newman ---\n",
      "Modularity: 0.0168\n",
      "Partition Quality (Coverage, Performance): (0.9997, 0.1870)\n",
      "Found 34 communities.\n",
      "------------------------------\n",
      "\n",
      "Exporting Misinfo to GEXF...\n",
      "\n",
      ">>> Successfully exported graph to ../visualization/Misinfo_with_communities.gexf\n",
      "\n",
      "\n",
      "Analysis complete.\n",
      "Connection closed.\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "\n",
    "G_shares = nx.Graph()\n",
    "G_viral = nx.Graph()\n",
    "G_misinfo = nx.Graph()\n",
    "\n",
    "try:\n",
    "    driver = GraphDatabase.driver(URI, auth=AUTH)\n",
    "\n",
    "    print(\"Connecting to Neo4j and building NetworkX graph...\")\n",
    "\n",
    "    networkx_graph = get_graph_from_neo4j(driver)\n",
    "\n",
    "    print(\"Graph imported into NetworkX\")\n",
    "\n",
    "    user_nodes = {n for n, d in networkx_graph.nodes(data=True) if 'User' in d.get('labels', [])}\n",
    "\n",
    "    for u_node in user_nodes:\n",
    "        G_shares.add_node(u_node, **networkx_graph.nodes[u_node])\n",
    "        G_viral.add_node(u_node, **networkx_graph.nodes[u_node])\n",
    "        G_misinfo.add_node(u_node, **networkx_graph.nodes[u_node])\n",
    "\n",
    "    for u, v, data in networkx_graph.edges(data=True):\n",
    "        if u in user_nodes and v in user_nodes:\n",
    "            edge_type = data.get('type')\n",
    "            if edge_type == 'SHARES':\n",
    "                G_shares.add_edge(u, v, **data)\n",
    "            elif edge_type == 'VIRAL_SHARES':\n",
    "                G_viral.add_edge(u, v, **data)\n",
    "            elif edge_type == 'SHARES_MISINFORMATION':\n",
    "                G_misinfo.add_edge(u, v, **data)\n",
    "\n",
    "    G_shares.remove_nodes_from(list(nx.isolates(G_shares)))\n",
    "    G_viral.remove_nodes_from(list(nx.isolates(G_viral)))\n",
    "    G_misinfo.remove_nodes_from(list(nx.isolates(G_misinfo)))\n",
    "\n",
    "    graphs_to_process = [\n",
    "        (\"Shares\", G_shares),\n",
    "        (\"Viral\", G_viral),\n",
    "        (\"Misinfo\", G_misinfo)\n",
    "    ]\n",
    "\n",
    "    K_COMMUNITIES = 4\n",
    "\n",
    "    for graph_name, G in graphs_to_process:\n",
    "        analyze_graph_communities_parallel(G, graph_name, k_target=K_COMMUNITIES)\n",
    "\n",
    "    print(\"\\n\\nAnalysis complete.\")\n",
    "\n",
    "except Exception:\n",
    "    traceback.print_exc()\n",
    "finally:\n",
    "    if 'driver' in locals() and driver:\n",
    "        driver.close()\n",
    "        print(\"Connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f487a0c68efa35de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d37463d5604c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbe658b61ddc7c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9416ea14b4c94c47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763543d2dbbbc0a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a5be605001dee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80ef7762f081fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5c78c46817033",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lista01-ED-Grafos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
